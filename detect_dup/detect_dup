#!/bin/bash
#
# detect_dup_modular.sh - JavaScripté‡è¤‡æ¤œå‡ºãƒ„ãƒ¼ãƒ«ï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ©ãƒ¼ç‰ˆï¼‰
#
# ä½¿ã„æ–¹:
#   ./detect_dup_modular.sh [OPTIONS] <TARGET_DIR> [WINDOW_SIZE]
#
# ã‚ªãƒ—ã‚·ãƒ§ãƒ³:
#   -a, --all              ã™ã¹ã¦ã®æ¤œå‡ºã‚’å®Ÿè¡Œï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
#   -b, --basic            åŸºæœ¬çš„ãªé‡è¤‡æ¤œå‡ºã®ã¿
#   -s, --structural       æ§‹é€ çš„é‡è¤‡æ¤œå‡ºã®ã¿
#   -p, --patterns         ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹æ¤œå‡ºã®ã¿
#   -f, --functional       é–¢æ•°ãƒ»æ©Ÿèƒ½çš„é‡è¤‡æ¤œå‡ºã®ã¿
#   -t, --text             ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒ™ãƒ«é‡è¤‡æ¤œå‡ºã®ã¿
#   -w, --window-scan      è¤‡æ•°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã§ã‚¹ã‚­ãƒ£ãƒ³
#   -r, --range START:END  ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºç¯„å›²æŒ‡å®š (ä¾‹: 3:10)
#   -l, --list             åˆ©ç”¨å¯èƒ½ãªæ¤œå‡ºã‚¿ã‚¤ãƒ—ã‚’è¡¨ç¤º
#   -o, --output FORMAT    å‡ºåŠ›å½¢å¼ (console|json|csv)
#   -v, --verbose          è©³ç´°å‡ºåŠ›
#   -h, --help             ã“ã®ãƒ˜ãƒ«ãƒ—ã‚’è¡¨ç¤º
#
set -euo pipefail

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
DEFAULT_WINDOW=5
OUTPUT_FORMAT="console"
VERBOSE=false
WINDOW_SCAN=false
WINDOW_RANGE=""

# æ¤œå‡ºãƒ•ãƒ©ã‚°
RUN_ALL=true
RUN_BASIC=false
RUN_STRUCTURAL=false
RUN_PATTERNS=false
RUN_FUNCTIONAL=false
RUN_TEXT=false

# ã‚«ãƒ©ãƒ¼å‡ºåŠ›
if [[ -t 1 ]]; then
  RED='\033[0;31m'
  GREEN='\033[0;32m'
  YELLOW='\033[1;33m'
  BLUE='\033[0;34m'
  PURPLE='\033[0;35m'
  CYAN='\033[0;36m'
  NC='\033[0m' # No Color
else
  RED='' GREEN='' YELLOW='' BLUE='' PURPLE='' CYAN='' NC=''
fi

# ãƒ­ã‚°é–¢æ•°
log() { 
  if [[ "$VERBOSE" == true ]]; then
    echo -e "${BLUE}[$(date '+%H:%M:%S')]${NC} $*" >&2
  fi
}

info() { echo -e "${GREEN}[INFO]${NC} $*" >&2; }
warn() { echo -e "${YELLOW}[WARN]${NC} $*" >&2; }
error() { echo -e "${RED}[ERROR]${NC} $*" >&2; }
section() { echo -e "\n${PURPLE}=== $* ===${NC}"; }

# ãƒ˜ãƒ«ãƒ—è¡¨ç¤º
show_help() {
  cat << 'EOF'
detect_dup_modular.sh - JavaScripté‡è¤‡æ¤œå‡ºãƒ„ãƒ¼ãƒ«

ä½¿ã„æ–¹:
  ./detect_dup_modular.sh [OPTIONS] <TARGET_DIR> [WINDOW_SIZE]

æ¤œå‡ºã‚¿ã‚¤ãƒ—:
  -a, --all              ã™ã¹ã¦ã®æ¤œå‡ºã‚’å®Ÿè¡Œï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
  -b, --basic            åŸºæœ¬çš„ãªé‡è¤‡æ¤œå‡ºã®ã¿
  -s, --structural       æ§‹é€ çš„é‡è¤‡æ¤œå‡ºã®ã¿  
  -p, --patterns         ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹æ¤œå‡ºã®ã¿
  -f, --functional       é–¢æ•°ãƒ»æ©Ÿèƒ½çš„é‡è¤‡æ¤œå‡ºã®ã¿
  -t, --text             ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒ™ãƒ«é‡è¤‡æ¤œå‡ºã®ã¿

ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚ªãƒ—ã‚·ãƒ§ãƒ³:
  -w, --window-scan      è¤‡æ•°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã§ã‚¹ã‚­ãƒ£ãƒ³ (3,5,7,10,15,20)
  -r, --range START:END  ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºç¯„å›²æŒ‡å®š (ä¾‹: 3:10)

å‡ºåŠ›ã‚ªãƒ—ã‚·ãƒ§ãƒ³:
  -o, --output FORMAT    å‡ºåŠ›å½¢å¼ (console|json|csv)
  -v, --verbose          è©³ç´°å‡ºåŠ›ã‚’æœ‰åŠ¹åŒ–

ãã®ä»–:
  -l, --list             åˆ©ç”¨å¯èƒ½ãªæ¤œå‡ºã‚¿ã‚¤ãƒ—ã‚’è¡¨ç¤º
  -h, --help             ã“ã®ãƒ˜ãƒ«ãƒ—ã‚’è¡¨ç¤º

ä¾‹:
  ./detect_dup_modular.sh -b ./src 5              # åŸºæœ¬æ¤œå‡ºã®ã¿
  ./detect_dup_modular.sh -s -o json ./project    # æ§‹é€ æ¤œå‡ºã‚’JSONå‡ºåŠ›
  ./detect_dup_modular.sh -p -f ./src             # ãƒ‘ã‚¿ãƒ¼ãƒ³+é–¢æ•°æ¤œå‡º
  ./detect_dup_modular.sh -v -a ./project 10      # å…¨æ¤œå‡ºã€è©³ç´°å‡ºåŠ›
  ./detect_dup_modular.sh -w ./src                # è¤‡æ•°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã§ã‚¹ã‚­ãƒ£ãƒ³
  ./detect_dup_modular.sh -r 5:15 ./project       # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º5-15ã§ã‚¹ã‚­ãƒ£ãƒ³
  ./detect_dup_modular.sh -t -w -o json ./src     # ãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡ºã‚’è¤‡æ•°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§å®Ÿè¡Œ

æ¤œå‡ºã‚¿ã‚¤ãƒ—è©³ç´°:
  basic      : å¤šè¡Œãƒ†ã‚­ã‚¹ãƒˆé‡è¤‡ã€åŸºæœ¬çš„ãªåŒä¸€ã‚³ãƒ¼ãƒ‰
  structural : åˆ¶å¾¡æ§‹é€ ã€ASTåŸºç›¤ã®æ§‹é€ çš„é‡è¤‡
  patterns   : æ­£è¦è¡¨ç¾ã€APIä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³
  functional : é–¢æ•°å®šç¾©ã€ãƒ¡ã‚½ãƒƒãƒ‰é‡è¤‡
  text       : æ–‡å­—åˆ—ã€ã‚³ãƒ¡ãƒ³ãƒˆã€ãƒªãƒ†ãƒ©ãƒ«é‡è¤‡
EOF
}

# æ¤œå‡ºã‚¿ã‚¤ãƒ—ä¸€è¦§è¡¨ç¤º
show_detection_types() {
  cat << 'EOF'
åˆ©ç”¨å¯èƒ½ãªæ¤œå‡ºã‚¿ã‚¤ãƒ—:

ğŸ“ TEXT (ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒ™ãƒ«)
  â€¢ å¤šè¡Œãƒ†ã‚­ã‚¹ãƒˆé‡è¤‡ï¼ˆã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼‰
  â€¢ æ–‡å­—åˆ—ãƒªãƒ†ãƒ©ãƒ«é‡è¤‡
  â€¢ ã‚³ãƒ¡ãƒ³ãƒˆé‡è¤‡
  â€¢ å¤‰æ•°åãƒ‘ã‚¿ãƒ¼ãƒ³

ğŸ—ï¸  STRUCTURAL (æ§‹é€ çš„)
  â€¢ åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼é‡è¤‡ï¼ˆif-else, switchï¼‰
  â€¢ ãƒ«ãƒ¼ãƒ—æ§‹é€ é‡è¤‡ï¼ˆfor, whileï¼‰
  â€¢ try-catchæ§‹é€ 
  â€¢ ãƒã‚¹ãƒˆæ§‹é€ ãƒ‘ã‚¿ãƒ¼ãƒ³

ğŸ”§ FUNCTIONAL (é–¢æ•°ãƒ»æ©Ÿèƒ½çš„)
  â€¢ é–¢æ•°å®šç¾©é‡è¤‡
  â€¢ ãƒ¡ã‚½ãƒƒãƒ‰å®Ÿè£…é‡è¤‡
  â€¢ ã‚¢ãƒ­ãƒ¼é–¢æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³
  â€¢ ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°

ğŸ¯ PATTERNS (ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹)
  â€¢ APIä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³
  â€¢ é…åˆ—æ“ä½œãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆmap, filter, reduceï¼‰
  â€¢ Promiseãƒã‚§ãƒ¼ãƒ³
  â€¢ æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³

âš¡ BASIC (åŸºæœ¬çš„)
  â€¢ å¤šè¡Œé‡è¤‡ï¼ˆæŒ‡å®šè¡Œæ•°ï¼‰
  â€¢ å˜ç´”ãªã‚³ãƒ”ãƒ¼&ãƒšãƒ¼ã‚¹ãƒˆæ¤œå‡º
  â€¢ è­˜åˆ¥å­æ­£è¦åŒ–ã«ã‚ˆã‚‹æ¤œå‡º
EOF
}

# å¼•æ•°è§£æ
parse_arguments() {
  while [[ $# -gt 0 ]]; do
    case $1 in
      -a|--all)
        RUN_ALL=true
        shift
        ;;
      -b|--basic)
        RUN_ALL=false
        RUN_BASIC=true
        shift
        ;;
      -s|--structural)
        RUN_ALL=false
        RUN_STRUCTURAL=true
        shift
        ;;
      -p|--patterns)
        RUN_ALL=false
        RUN_PATTERNS=true
        shift
        ;;
      -f|--functional)
        RUN_ALL=false
        RUN_FUNCTIONAL=true
        shift
        ;;
      -t|--text)
        RUN_ALL=false
        RUN_TEXT=true
        shift
        ;;
      -w|--window-scan)
        WINDOW_SCAN=true
        shift
        ;;
      -r|--range)
        WINDOW_RANGE="$2"
        shift 2
        ;;
      -o|--output)
        OUTPUT_FORMAT="$2"
        shift 2
        ;;
      -v|--verbose)
        VERBOSE=true
        shift
        ;;
      -l|--list)
        show_detection_types
        exit 0
        ;;
      -h|--help)
        show_help
        exit 0
        ;;
      -*)
        error "ä¸æ˜ãªã‚ªãƒ—ã‚·ãƒ§ãƒ³: $1"
        echo "ãƒ˜ãƒ«ãƒ—ã¯ -h ã¾ãŸã¯ --help ã§ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
        exit 1
        ;;
      *)
        break
        ;;
    esac
  done

  # ä½ç½®å¼•æ•°ã®å‡¦ç†
  if [[ $# -lt 1 ]]; then
    error "TARGET_DIR ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
    show_help
    exit 1
  fi

  TARGET_DIR="$1"
  
  # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã®å‡¦ç†
  if [[ "$WINDOW_SCAN" == true || -n "$WINDOW_RANGE" ]]; then
    # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚¹ã‚­ãƒ£ãƒ³ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã€WINDOW_SIZEå¼•æ•°ã¯ç„¡è¦–
    WINDOW="$DEFAULT_WINDOW"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼ˆå®Ÿéš›ã«ã¯ä½¿ç”¨ã•ã‚Œãªã„ï¼‰
  else
    WINDOW="${2:-$DEFAULT_WINDOW}"
  fi

  # å…¥åŠ›æ¤œè¨¼
  if [[ ! -d "$TARGET_DIR" ]]; then
    error "ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: $TARGET_DIR"
    exit 1
  fi

  # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç¯„å›²ã®æ¤œè¨¼
  if [[ -n "$WINDOW_RANGE" ]]; then
    if [[ ! "$WINDOW_RANGE" =~ ^[0-9]+:[0-9]+$ ]]; then
      error "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç¯„å›²ã¯ 'START:END' å½¢å¼ã§æŒ‡å®šã—ã¦ãã ã•ã„: $WINDOW_RANGE"
      exit 1
    fi
    
    local start_window end_window
    start_window=$(echo "$WINDOW_RANGE" | cut -d: -f1)
    end_window=$(echo "$WINDOW_RANGE" | cut -d: -f2)
    
    if [[ "$start_window" -ge "$end_window" ]]; then
      error "é–‹å§‹ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã¯çµ‚äº†ã‚µã‚¤ã‚ºã‚ˆã‚Šå°ã•ãã—ã¦ãã ã•ã„: $WINDOW_RANGE"
      exit 1
    fi
    
    if [[ "$start_window" -lt 1 || "$end_window" -gt 50 ]]; then
      error "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã¯1-50ã®ç¯„å›²ã§æŒ‡å®šã—ã¦ãã ã•ã„: $WINDOW_RANGE"
      exit 1
    fi
  fi

  if ! [[ "$WINDOW" =~ ^[0-9]+$ ]] || [[ "$WINDOW" -lt 1 ]]; then
    error "WINDOW_SIZE ã¯æ­£ã®æ•´æ•°ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: $WINDOW"
    exit 1
  fi

  if [[ ! "$OUTPUT_FORMAT" =~ ^(console|json|csv)$ ]]; then
    error "å‡ºåŠ›å½¢å¼ã¯ console, json, csv ã®ã„ãšã‚Œã‹ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: $OUTPUT_FORMAT"
    exit 1
  fi
}

# ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å¯¾å¿œ
setup_platform() {
  # realpathå¯¾å¿œ
  if command -v realpath >/dev/null 2>&1; then
    GET_REL_PATH() { 
      realpath --relative-to="$1" "$2" 2>/dev/null || echo "$2"
    }
  elif command -v python3 >/dev/null 2>&1; then
    GET_REL_PATH() {
      python3 -c "import os; print(os.path.relpath('$2', '$1'))" 2>/dev/null || echo "$2"
    }
  else
    GET_REL_PATH() { echo "$2"; }
  fi

  # ãƒãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰
  if command -v md5sum >/dev/null 2>&1; then
    HASH_CMD="md5sum"
  elif command -v md5 >/dev/null 2>&1; then
    HASH_CMD="md5"
  else
    error "MD5ãƒãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
    exit 1
  fi
}

# ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
setup_temp() {
  TMP=$(mktemp -d)
  trap 'rm -rf "$TMP"' EXIT INT TERM

  NORM="$TMP/norm"
  RESULTS="$TMP/results"
  mkdir -p "$NORM" "$RESULTS"

  log "ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ: $TMP"
}

# JavaScriptæ­£è¦åŒ–
normalize_js() {
  local input="$1" output="$2"
  
  # Node.jsãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆ
  if command -v node >/dev/null 2>&1; then
    node -e "
      const fs = require('fs');
      try {
        let code = fs.readFileSync('$input', 'utf8');
        
        // ã‚³ãƒ¡ãƒ³ãƒˆé™¤å»
        code = code
          .replace(/\/\*[\s\S]*?\*\//g, ' ')
          .replace(/\/\/.*$/gm, ' ');
        
        // æ–‡å­—åˆ—æ­£è¦åŒ–
        code = code
          .replace(/(['\"\`])(?:\\\\.|(?!\1)[^\\\\])*\1/g, '\"STR\"')
          .replace(/\b\d+\.?\d*\b/g, 'NUM')
          .replace(/\b[a-zA-Z_$][a-zA-Z0-9_$]*\b/g, 'VAR');
        
        fs.writeFileSync('$output', code);
      } catch(e) {
        process.exit(1);
      }
    " 2>/dev/null && return 0
  fi
  
  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
  sed -E '
    s|//[^"'"'"']*$||g
    s|/\*[^*]*\*/||g
    s/"[^"]*"/"STR"/g
    s/'"'"'[^'"'"']*'"'"'/"STR"/g
    s/\b[0-9]+(\.[0-9]+)?\b/NUM/g
    s/\b[a-zA-Z_$][a-zA-Z0-9_$]*\b/VAR/g
  ' "$input" > "$output"
}

# ãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™
prepare_files() {
  log "JavaScript ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ä¸­..."
  
  find "$TARGET_DIR" -name "*.js" -type f ! -path "*/node_modules/*" ! -name "*.min.js" > "$TMP/js_files"
  
  local file_count
  file_count=$(wc -l < "$TMP/js_files")
  
  if [[ "$file_count" -eq 0 ]]; then
    warn "JavaScript ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
    exit 0
  fi
  
  info "$file_count å€‹ã®JavaScriptãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹"
  
  log "ãƒ•ã‚¡ã‚¤ãƒ«æ­£è¦åŒ–ä¸­..."
  while IFS= read -r f; do
    local rel_path
    rel_path=$(GET_REL_PATH "$TARGET_DIR" "$f")
    local out="$NORM/$rel_path"
    mkdir -p "$(dirname "$out")"
    normalize_js "$f" "$out"
  done < "$TMP/js_files"
  
  log "æ­£è¦åŒ–å®Œäº†"
}

# ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºãƒªã‚¹ãƒˆç”Ÿæˆ
generate_window_sizes() {
  if [[ "$WINDOW_SCAN" == true ]]; then
    echo "3 5 7 10 15 20"
  elif [[ -n "$WINDOW_RANGE" ]]; then
    local start_window end_window
    start_window=$(echo "$WINDOW_RANGE" | cut -d: -f1)
    end_window=$(echo "$WINDOW_RANGE" | cut -d: -f2)
    seq "$start_window" "$end_window"
  else
    echo "$WINDOW"
  fi
}

# è¤‡æ•°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ã®æ¤œå‡ºå®Ÿè¡Œ
run_multi_window_detection() {
  local detect_function="$1"
  local window_sizes
  window_sizes=$(generate_window_sizes)
  
  for window_size in $window_sizes; do
    log "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º $window_size ã§æ¤œå‡ºå®Ÿè¡Œä¸­..."
    CURRENT_WINDOW="$window_size"
    $detect_function
  done
}
# å‡ºåŠ›ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
output_result() {
  local type="$1" hash="$2" locations="$3" window_size="${4:-}"
  
  # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºæƒ…å ±ã‚’å«ã‚ã‚‹
  local full_type="$type"
  if [[ -n "$window_size" ]]; then
    full_type="${type}_W${window_size}"
  fi
  
  case "$OUTPUT_FORMAT" in
    json)
      local window_field=""
      if [[ -n "$window_size" ]]; then
        window_field=",\"window_size\":$window_size"
      fi
      echo "{\"type\":\"$full_type\",\"hash\":\"$hash\",\"locations\":[$locations]$window_field}," >> "$RESULTS/output.json"
      ;;
    csv)
      echo "$full_type,$hash,\"$locations\",$window_size" >> "$RESULTS/output.csv"
      ;;
    console|*)
      if [[ -n "$window_size" ]]; then
        echo -e "${CYAN}[$full_type]${NC} Hash: ${hash:0:8} ${YELLOW}(Window: $window_size)${NC}"
      else
        echo -e "${CYAN}[$type]${NC} Hash: ${hash:0:8}"
      fi
      echo "$locations" | sed 's/^/  /'
      echo
      ;;
  esac
}

# === æ¤œå‡ºé–¢æ•°ç¾¤ ===

# ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒ™ãƒ«é‡è¤‡æ¤œå‡º
detect_text_duplicates() {
  local window_size="${CURRENT_WINDOW:-$WINDOW}"
  
  section "ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒ™ãƒ«é‡è¤‡æ¤œå‡º (ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º: $window_size)"
  
  # 1. å¤šè¡Œãƒ†ã‚­ã‚¹ãƒˆé‡è¤‡
  log "å¤šè¡Œé‡è¤‡æ¤œå‡ºä¸­ (ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦: $window_size è¡Œ)"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    awk -v window="$window_size" -v file="$f" '
    {
      lines[NR] = $0
      if (NR >= window) {
        block = ""
        for (i = NR - window + 1; i <= NR; i++) {
          block = block lines[i] "\n"
        }
        cmd = "echo \"" block "\" | '"$HASH_CMD"'"
        cmd | getline hash
        close(cmd)
        print substr(hash, 1, 32) "\t" file ":" (NR - window + 1)
      }
    }
    ' "$f"
  done > "$TMP/text_hashes_${window_size}"
  
  if [[ -s "$TMP/text_hashes_${window_size}" ]]; then
    sort "$TMP/text_hashes_${window_size}" | uniq -d | while IFS=

# æ§‹é€ çš„é‡è¤‡æ¤œå‡º
detect_structural_duplicates() {
  section "æ§‹é€ çš„é‡è¤‡æ¤œå‡º"
  
  # 1. åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼é‡è¤‡ï¼ˆif-elseï¼‰
  log "if-elseæ§‹é€ é‡è¤‡æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    grep -n "if\|else" "$f" | while IFS=: read -r line_num content; do
      local normalized
      normalized=$(echo "$content" | sed -E 's/VAR[0-9]*/VAR/g; s/NUM/NUM/g; s/[[:space:]]+//g')
      local hash
      hash=$(echo "$normalized" | $HASH_CMD | cut -d' ' -f1)
      echo "$hash	$f:$line_num"
    done
  done > "$TMP/structural_if"
  
  if [[ -s "$TMP/structural_if" ]]; then
    sort "$TMP/structural_if" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/structural_if" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "STRUCTURAL_IF" "$hash" "$locations"
      fi
    done
  fi
  
  # 2. ãƒ«ãƒ¼ãƒ—æ§‹é€ é‡è¤‡
  log "ãƒ«ãƒ¼ãƒ—æ§‹é€ é‡è¤‡æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    grep -n "for\|while" "$f" | while IFS=: read -r line_num content; do
      local normalized
      normalized=$(echo "$content" | sed -E 's/VAR[0-9]*/VAR/g; s/NUM/NUM/g; s/[[:space:]]+//g')
      local hash
      hash=$(echo "$normalized" | $HASH_CMD | cut -d' ' -f1)
      echo "$hash	$f:$line_num"
    done
  done > "$TMP/structural_loop"
  
  if [[ -s "$TMP/structural_loop" ]]; then
    sort "$TMP/structural_loop" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/structural_loop" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "STRUCTURAL_LOOP" "$hash" "$locations"
      fi
    done
  fi
}

# ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹é‡è¤‡æ¤œå‡º
detect_pattern_duplicates() {
  section "ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹é‡è¤‡æ¤œå‡º"
  
  # 1. é…åˆ—æ“ä½œãƒ‘ã‚¿ãƒ¼ãƒ³
  log "é…åˆ—æ“ä½œãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    grep -n "\.map\|\.filter\|\.reduce" "$f" | while IFS=: read -r line_num content; do
      local pattern
      pattern=$(echo "$content" | sed -E 's/\.map\([^)]*\)/.map(F)/g; s/\.filter\([^)]*\)/.filter(F)/g; s/\.reduce\([^)]*\)/.reduce(F)/g')
      local hash
      hash=$(echo "$pattern" | $HASH_CMD | cut -d' ' -f1)
      echo "$hash	$f:$line_num"
    done
  done > "$TMP/pattern_array"
  
  if [[ -s "$TMP/pattern_array" ]]; then
    sort "$TMP/pattern_array" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/pattern_array" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "PATTERN_ARRAY" "$hash" "$locations"
      fi
    done
  fi
  
  # 2. Promiseãƒã‚§ãƒ¼ãƒ³
  log "Promiseãƒã‚§ãƒ¼ãƒ³æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    grep -n "\.then\|\.catch" "$f" | while IFS=: read -r line_num content; do
      local pattern
      pattern=$(echo "$content" | sed -E 's/\.then\([^)]*\)/.then(F)/g; s/\.catch\([^)]*\)/.catch(F)/g')
      local hash
      hash=$(echo "$pattern" | $HASH_CMD | cut -d' ' -f1)
      echo "$hash	$f:$line_num"
    done
  done > "$TMP/pattern_promise"
  
  if [[ -s "$TMP/pattern_promise" ]]; then
    sort "$TMP/pattern_promise" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/pattern_promise" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "PATTERN_PROMISE" "$hash" "$locations"
      fi
    done
  fi
}

# é–¢æ•°çš„é‡è¤‡æ¤œå‡º
detect_functional_duplicates() {
  section "é–¢æ•°çš„é‡è¤‡æ¤œå‡º"
  
  # 1. é–¢æ•°å®šç¾©é‡è¤‡
  log "é–¢æ•°å®šç¾©é‡è¤‡æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    grep -n "function\|=>" "$f" | while IFS=: read -r line_num content; do
      local normalized
      normalized=$(echo "$content" | sed -E 's/function[[:space:]]+VAR/function VAR/g; s/VAR[0-9]*/VAR/g; s/[[:space:]]+//g')
      local hash
      hash=$(echo "$normalized" | $HASH_CMD | cut -d' ' -f1)
      echo "$hash	$f:$line_num"
    done
  done > "$TMP/functional_def"
  
  if [[ -s "$TMP/functional_def" ]]; then
    sort "$TMP/functional_def" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/functional_def" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "FUNCTIONAL_DEF" "$hash" "$locations"
      fi
    done
  fi
}

# åŸºæœ¬çš„é‡è¤‡æ¤œå‡º
detect_basic_duplicates() {
  local window_size="${CURRENT_WINDOW:-$WINDOW}"
  
  section "åŸºæœ¬çš„é‡è¤‡æ¤œå‡º (ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º: $window_size)"
  
  # å¤šè¡Œé‡è¤‡ï¼ˆç°¡æ˜“ç‰ˆï¼‰
  log "åŸºæœ¬å¤šè¡Œé‡è¤‡æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    awk -v window="$window_size" -v file="$f" '
    {
      for(i=1; i<=NF; i++) {
        if (NF >= window) {
          block = ""
          for(j=i; j<i+window && j<=NF; j++) {
            block = block $j " "
          }
          if (length(block) > 10) {
            cmd = "echo \"" block "\" | '"$HASH_CMD"'"
            cmd | getline hash
            close(cmd)
            print substr(hash, 1, 32) "\t" file ":" NR
          }
        }
      }
    }
    ' "$f"
  done > "$TMP/basic_hashes_${window_size}"
  
  if [[ -s "$TMP/basic_hashes_${window_size}" ]]; then
    sort "$TMP/basic_hashes_${window_size}" | uniq -d | while IFS=

# çµæœå‡ºåŠ›ã®åˆæœŸåŒ–
init_output() {
  case "$OUTPUT_FORMAT" in
    json)
      echo "[" > "$RESULTS/output.json"
      ;;
    csv)
      echo "type,hash,locations,window_size" > "$RESULTS/output.csv"
      ;;
  esac
}

# çµæœå‡ºåŠ›ã®çµ‚äº†å‡¦ç†
finalize_output() {
  case "$OUTPUT_FORMAT" in
    json)
      # æœ€å¾Œã®ã‚«ãƒ³ãƒã‚’å‰Šé™¤ã—ã¦JSONã‚’é–‰ã˜ã‚‹
      if [[ -s "$RESULTS/output.json" ]]; then
        sed -i '$ s/,$//' "$RESULTS/output.json" 2>/dev/null || true
      fi
      echo "]" >> "$RESULTS/output.json"
      cat "$RESULTS/output.json"
      ;;
    csv)
      cat "$RESULTS/output.csv"
      ;;
    console)
      section "æ¤œå‡ºå®Œäº†"
      info "é‡è¤‡æ¤œå‡ºå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ"
      ;;
  esac
}

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
main() {
  parse_arguments "$@"
  setup_platform
  setup_temp
  prepare_files
  init_output
  
  # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºæƒ…å ±è¡¨ç¤º
  local window_info
  if [[ "$WINDOW_SCAN" == true ]]; then
    window_info="è¤‡æ•°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚¹ã‚­ãƒ£ãƒ³ (3,5,7,10,15,20)"
  elif [[ -n "$WINDOW_RANGE" ]]; then
    window_info="ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç¯„å›²ã‚¹ã‚­ãƒ£ãƒ³ ($WINDOW_RANGE)"
  else
    window_info="å›ºå®šã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º ($WINDOW)"
  fi
  
  info "é‡è¤‡æ¤œå‡ºé–‹å§‹: $TARGET_DIR ($window_info)"
  
  # æ¤œå‡ºå®Ÿè¡Œ
  if [[ "$WINDOW_SCAN" == true || -n "$WINDOW_RANGE" ]]; then
    # è¤‡æ•°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã§ã®æ¤œå‡º
    if [[ "$RUN_ALL" == true ]]; then
      run_multi_window_detection detect_text_duplicates
      detect_structural_duplicates  # æ§‹é€ çš„æ¤œå‡ºã¯ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã«ä¾å­˜ã—ãªã„
      detect_pattern_duplicates
      detect_functional_duplicates
      run_multi_window_detection detect_basic_duplicates
    else
      [[ "$RUN_TEXT" == true ]] && run_multi_window_detection detect_text_duplicates
      [[ "$RUN_STRUCTURAL" == true ]] && detect_structural_duplicates
      [[ "$RUN_PATTERNS" == true ]] && detect_pattern_duplicates
      [[ "$RUN_FUNCTIONAL" == true ]] && detect_functional_duplicates
      [[ "$RUN_BASIC" == true ]] && run_multi_window_detection detect_basic_duplicates
    fi
  else
    # å˜ä¸€ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã§ã®æ¤œå‡º
    if [[ "$RUN_ALL" == true ]]; then
      detect_text_duplicates
      detect_structural_duplicates
      detect_pattern_duplicates
      detect_functional_duplicates
      detect_basic_duplicates
    else
      [[ "$RUN_TEXT" == true ]] && detect_text_duplicates
      [[ "$RUN_STRUCTURAL" == true ]] && detect_structural_duplicates
      [[ "$RUN_PATTERNS" == true ]] && detect_pattern_duplicates
      [[ "$RUN_FUNCTIONAL" == true ]] && detect_functional_duplicates
      [[ "$RUN_BASIC" == true ]] && detect_basic_duplicates
    fi
  fi
  
  finalize_output
}

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
main "$@"\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/text_hashes_${window_size}" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "TEXT_MULTILINE" "$hash" "$locations" "$window_size"
      fi
    done
  fi
  
  # 2. æ–‡å­—åˆ—ãƒªãƒ†ãƒ©ãƒ«é‡è¤‡
  log "æ–‡å­—åˆ—ãƒªãƒ†ãƒ©ãƒ«é‡è¤‡æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f -exec grep -Hn "\"STR\"" {} \; | \
  while IFS=: read -r file line content; do
    local pattern_hash
    pattern_hash=$(echo "$content" | $HASH_CMD | cut -d' ' -f1)
    echo "$pattern_hash	$file:$line"
  done | sort | uniq -d | while IFS=

# æ§‹é€ çš„é‡è¤‡æ¤œå‡º
detect_structural_duplicates() {
  section "æ§‹é€ çš„é‡è¤‡æ¤œå‡º"
  
  # 1. åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼é‡è¤‡ï¼ˆif-elseï¼‰
  log "if-elseæ§‹é€ é‡è¤‡æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    grep -n "if\|else" "$f" | while IFS=: read -r line_num content; do
      local normalized
      normalized=$(echo "$content" | sed -E 's/VAR[0-9]*/VAR/g; s/NUM/NUM/g; s/[[:space:]]+//g')
      local hash
      hash=$(echo "$normalized" | $HASH_CMD | cut -d' ' -f1)
      echo "$hash	$f:$line_num"
    done
  done > "$TMP/structural_if"
  
  if [[ -s "$TMP/structural_if" ]]; then
    sort "$TMP/structural_if" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/structural_if" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "STRUCTURAL_IF" "$hash" "$locations"
      fi
    done
  fi
  
  # 2. ãƒ«ãƒ¼ãƒ—æ§‹é€ é‡è¤‡
  log "ãƒ«ãƒ¼ãƒ—æ§‹é€ é‡è¤‡æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    grep -n "for\|while" "$f" | while IFS=: read -r line_num content; do
      local normalized
      normalized=$(echo "$content" | sed -E 's/VAR[0-9]*/VAR/g; s/NUM/NUM/g; s/[[:space:]]+//g')
      local hash
      hash=$(echo "$normalized" | $HASH_CMD | cut -d' ' -f1)
      echo "$hash	$f:$line_num"
    done
  done > "$TMP/structural_loop"
  
  if [[ -s "$TMP/structural_loop" ]]; then
    sort "$TMP/structural_loop" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/structural_loop" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "STRUCTURAL_LOOP" "$hash" "$locations"
      fi
    done
  fi
}

# ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹é‡è¤‡æ¤œå‡º
detect_pattern_duplicates() {
  section "ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹é‡è¤‡æ¤œå‡º"
  
  # 1. é…åˆ—æ“ä½œãƒ‘ã‚¿ãƒ¼ãƒ³
  log "é…åˆ—æ“ä½œãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    grep -n "\.map\|\.filter\|\.reduce" "$f" | while IFS=: read -r line_num content; do
      local pattern
      pattern=$(echo "$content" | sed -E 's/\.map\([^)]*\)/.map(F)/g; s/\.filter\([^)]*\)/.filter(F)/g; s/\.reduce\([^)]*\)/.reduce(F)/g')
      local hash
      hash=$(echo "$pattern" | $HASH_CMD | cut -d' ' -f1)
      echo "$hash	$f:$line_num"
    done
  done > "$TMP/pattern_array"
  
  if [[ -s "$TMP/pattern_array" ]]; then
    sort "$TMP/pattern_array" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/pattern_array" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "PATTERN_ARRAY" "$hash" "$locations"
      fi
    done
  fi
  
  # 2. Promiseãƒã‚§ãƒ¼ãƒ³
  log "Promiseãƒã‚§ãƒ¼ãƒ³æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    grep -n "\.then\|\.catch" "$f" | while IFS=: read -r line_num content; do
      local pattern
      pattern=$(echo "$content" | sed -E 's/\.then\([^)]*\)/.then(F)/g; s/\.catch\([^)]*\)/.catch(F)/g')
      local hash
      hash=$(echo "$pattern" | $HASH_CMD | cut -d' ' -f1)
      echo "$hash	$f:$line_num"
    done
  done > "$TMP/pattern_promise"
  
  if [[ -s "$TMP/pattern_promise" ]]; then
    sort "$TMP/pattern_promise" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/pattern_promise" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "PATTERN_PROMISE" "$hash" "$locations"
      fi
    done
  fi
}

# é–¢æ•°çš„é‡è¤‡æ¤œå‡º
detect_functional_duplicates() {
  section "é–¢æ•°çš„é‡è¤‡æ¤œå‡º"
  
  # 1. é–¢æ•°å®šç¾©é‡è¤‡
  log "é–¢æ•°å®šç¾©é‡è¤‡æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    grep -n "function\|=>" "$f" | while IFS=: read -r line_num content; do
      local normalized
      normalized=$(echo "$content" | sed -E 's/function[[:space:]]+VAR/function VAR/g; s/VAR[0-9]*/VAR/g; s/[[:space:]]+//g')
      local hash
      hash=$(echo "$normalized" | $HASH_CMD | cut -d' ' -f1)
      echo "$hash	$f:$line_num"
    done
  done > "$TMP/functional_def"
  
  if [[ -s "$TMP/functional_def" ]]; then
    sort "$TMP/functional_def" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/functional_def" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "FUNCTIONAL_DEF" "$hash" "$locations"
      fi
    done
  fi
}

# åŸºæœ¬çš„é‡è¤‡æ¤œå‡º
detect_basic_duplicates() {
  section "åŸºæœ¬çš„é‡è¤‡æ¤œå‡º"
  
  # å¤šè¡Œé‡è¤‡ï¼ˆç°¡æ˜“ç‰ˆï¼‰
  log "åŸºæœ¬å¤šè¡Œé‡è¤‡æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    awk -v window="$WINDOW" -v file="$f" '
    {
      for(i=1; i<=NF; i++) {
        if (NF >= window) {
          block = ""
          for(j=i; j<i+window && j<=NF; j++) {
            block = block $j " "
          }
          if (length(block) > 10) {
            cmd = "echo \"" block "\" | '"$HASH_CMD"'"
            cmd | getline hash
            close(cmd)
            print substr(hash, 1, 32) "\t" file ":" NR
          }
        }
      }
    }
    ' "$f"
  done > "$TMP/basic_hashes"
  
  if [[ -s "$TMP/basic_hashes" ]]; then
    sort "$TMP/basic_hashes" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/basic_hashes" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "BASIC_DUPLICATE" "$hash" "$locations"
      fi
    done
  fi
}

# çµæœå‡ºåŠ›ã®åˆæœŸåŒ–
init_output() {
  case "$OUTPUT_FORMAT" in
    json)
      echo "[" > "$RESULTS/output.json"
      ;;
    csv)
      echo "type,hash,locations" > "$RESULTS/output.csv"
      ;;
  esac
}

# çµæœå‡ºåŠ›ã®çµ‚äº†å‡¦ç†
finalize_output() {
  case "$OUTPUT_FORMAT" in
    json)
      # æœ€å¾Œã®ã‚«ãƒ³ãƒã‚’å‰Šé™¤ã—ã¦JSONã‚’é–‰ã˜ã‚‹
      if [[ -s "$RESULTS/output.json" ]]; then
        sed -i '$ s/,$//' "$RESULTS/output.json" 2>/dev/null || true
      fi
      echo "]" >> "$RESULTS/output.json"
      cat "$RESULTS/output.json"
      ;;
    csv)
      cat "$RESULTS/output.csv"
      ;;
    console)
      section "æ¤œå‡ºå®Œäº†"
      info "é‡è¤‡æ¤œå‡ºå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ"
      ;;
  esac
}

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
main() {
  parse_arguments "$@"
  setup_platform
  setup_temp
  prepare_files
  init_output
  
  info "é‡è¤‡æ¤œå‡ºé–‹å§‹: $TARGET_DIR (ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º: $WINDOW)"
  
  # æ¤œå‡ºå®Ÿè¡Œ
  if [[ "$RUN_ALL" == true ]]; then
    detect_text_duplicates
    detect_structural_duplicates
    detect_pattern_duplicates
    detect_functional_duplicates
    detect_basic_duplicates
  else
    [[ "$RUN_TEXT" == true ]] && detect_text_duplicates
    [[ "$RUN_STRUCTURAL" == true ]] && detect_structural_duplicates
    [[ "$RUN_PATTERNS" == true ]] && detect_pattern_duplicates
    [[ "$RUN_FUNCTIONAL" == true ]] && detect_functional_duplicates
    [[ "$RUN_BASIC" == true ]] && detect_basic_duplicates
  fi
  
  finalize_output
}

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
main "$@"\t' read -r hash location; do
    local locations
    locations=$(grep "^$hash" <(find "$NORM" -name "*.js" -type f -exec grep -Hn "\"STR\"" {} \; | \
    while IFS=: read -r file line content; do
      local pattern_hash
      pattern_hash=$(echo "$content" | $HASH_CMD | cut -d' ' -f1)
      echo "$pattern_hash	$file:$line"
    done) | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
    output_result "TEXT_STRING" "$hash" "$locations" "$window_size"
  done
}

# æ§‹é€ çš„é‡è¤‡æ¤œå‡º
detect_structural_duplicates() {
  section "æ§‹é€ çš„é‡è¤‡æ¤œå‡º"
  
  # 1. åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼é‡è¤‡ï¼ˆif-elseï¼‰
  log "if-elseæ§‹é€ é‡è¤‡æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    grep -n "if\|else" "$f" | while IFS=: read -r line_num content; do
      local normalized
      normalized=$(echo "$content" | sed -E 's/VAR[0-9]*/VAR/g; s/NUM/NUM/g; s/[[:space:]]+//g')
      local hash
      hash=$(echo "$normalized" | $HASH_CMD | cut -d' ' -f1)
      echo "$hash	$f:$line_num"
    done
  done > "$TMP/structural_if"
  
  if [[ -s "$TMP/structural_if" ]]; then
    sort "$TMP/structural_if" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/structural_if" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "STRUCTURAL_IF" "$hash" "$locations"
      fi
    done
  fi
  
  # 2. ãƒ«ãƒ¼ãƒ—æ§‹é€ é‡è¤‡
  log "ãƒ«ãƒ¼ãƒ—æ§‹é€ é‡è¤‡æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    grep -n "for\|while" "$f" | while IFS=: read -r line_num content; do
      local normalized
      normalized=$(echo "$content" | sed -E 's/VAR[0-9]*/VAR/g; s/NUM/NUM/g; s/[[:space:]]+//g')
      local hash
      hash=$(echo "$normalized" | $HASH_CMD | cut -d' ' -f1)
      echo "$hash	$f:$line_num"
    done
  done > "$TMP/structural_loop"
  
  if [[ -s "$TMP/structural_loop" ]]; then
    sort "$TMP/structural_loop" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/structural_loop" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "STRUCTURAL_LOOP" "$hash" "$locations"
      fi
    done
  fi
}

# ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹é‡è¤‡æ¤œå‡º
detect_pattern_duplicates() {
  section "ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹é‡è¤‡æ¤œå‡º"
  
  # 1. é…åˆ—æ“ä½œãƒ‘ã‚¿ãƒ¼ãƒ³
  log "é…åˆ—æ“ä½œãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    grep -n "\.map\|\.filter\|\.reduce" "$f" | while IFS=: read -r line_num content; do
      local pattern
      pattern=$(echo "$content" | sed -E 's/\.map\([^)]*\)/.map(F)/g; s/\.filter\([^)]*\)/.filter(F)/g; s/\.reduce\([^)]*\)/.reduce(F)/g')
      local hash
      hash=$(echo "$pattern" | $HASH_CMD | cut -d' ' -f1)
      echo "$hash	$f:$line_num"
    done
  done > "$TMP/pattern_array"
  
  if [[ -s "$TMP/pattern_array" ]]; then
    sort "$TMP/pattern_array" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/pattern_array" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "PATTERN_ARRAY" "$hash" "$locations"
      fi
    done
  fi
  
  # 2. Promiseãƒã‚§ãƒ¼ãƒ³
  log "Promiseãƒã‚§ãƒ¼ãƒ³æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    grep -n "\.then\|\.catch" "$f" | while IFS=: read -r line_num content; do
      local pattern
      pattern=$(echo "$content" | sed -E 's/\.then\([^)]*\)/.then(F)/g; s/\.catch\([^)]*\)/.catch(F)/g')
      local hash
      hash=$(echo "$pattern" | $HASH_CMD | cut -d' ' -f1)
      echo "$hash	$f:$line_num"
    done
  done > "$TMP/pattern_promise"
  
  if [[ -s "$TMP/pattern_promise" ]]; then
    sort "$TMP/pattern_promise" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/pattern_promise" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "PATTERN_PROMISE" "$hash" "$locations"
      fi
    done
  fi
}

# é–¢æ•°çš„é‡è¤‡æ¤œå‡º
detect_functional_duplicates() {
  section "é–¢æ•°çš„é‡è¤‡æ¤œå‡º"
  
  # 1. é–¢æ•°å®šç¾©é‡è¤‡
  log "é–¢æ•°å®šç¾©é‡è¤‡æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    grep -n "function\|=>" "$f" | while IFS=: read -r line_num content; do
      local normalized
      normalized=$(echo "$content" | sed -E 's/function[[:space:]]+VAR/function VAR/g; s/VAR[0-9]*/VAR/g; s/[[:space:]]+//g')
      local hash
      hash=$(echo "$normalized" | $HASH_CMD | cut -d' ' -f1)
      echo "$hash	$f:$line_num"
    done
  done > "$TMP/functional_def"
  
  if [[ -s "$TMP/functional_def" ]]; then
    sort "$TMP/functional_def" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/functional_def" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "FUNCTIONAL_DEF" "$hash" "$locations"
      fi
    done
  fi
}

# åŸºæœ¬çš„é‡è¤‡æ¤œå‡º
detect_basic_duplicates() {
  section "åŸºæœ¬çš„é‡è¤‡æ¤œå‡º"
  
  # å¤šè¡Œé‡è¤‡ï¼ˆç°¡æ˜“ç‰ˆï¼‰
  log "åŸºæœ¬å¤šè¡Œé‡è¤‡æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    awk -v window="$WINDOW" -v file="$f" '
    {
      for(i=1; i<=NF; i++) {
        if (NF >= window) {
          block = ""
          for(j=i; j<i+window && j<=NF; j++) {
            block = block $j " "
          }
          if (length(block) > 10) {
            cmd = "echo \"" block "\" | '"$HASH_CMD"'"
            cmd | getline hash
            close(cmd)
            print substr(hash, 1, 32) "\t" file ":" NR
          }
        }
      }
    }
    ' "$f"
  done > "$TMP/basic_hashes"
  
  if [[ -s "$TMP/basic_hashes" ]]; then
    sort "$TMP/basic_hashes" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/basic_hashes" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "BASIC_DUPLICATE" "$hash" "$locations"
      fi
    done
  fi
}

# çµæœå‡ºåŠ›ã®åˆæœŸåŒ–
init_output() {
  case "$OUTPUT_FORMAT" in
    json)
      echo "[" > "$RESULTS/output.json"
      ;;
    csv)
      echo "type,hash,locations" > "$RESULTS/output.csv"
      ;;
  esac
}

# çµæœå‡ºåŠ›ã®çµ‚äº†å‡¦ç†
finalize_output() {
  case "$OUTPUT_FORMAT" in
    json)
      # æœ€å¾Œã®ã‚«ãƒ³ãƒã‚’å‰Šé™¤ã—ã¦JSONã‚’é–‰ã˜ã‚‹
      if [[ -s "$RESULTS/output.json" ]]; then
        sed -i '$ s/,$//' "$RESULTS/output.json" 2>/dev/null || true
      fi
      echo "]" >> "$RESULTS/output.json"
      cat "$RESULTS/output.json"
      ;;
    csv)
      cat "$RESULTS/output.csv"
      ;;
    console)
      section "æ¤œå‡ºå®Œäº†"
      info "é‡è¤‡æ¤œå‡ºå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ"
      ;;
  esac
}

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
main() {
  parse_arguments "$@"
  setup_platform
  setup_temp
  prepare_files
  init_output
  
  info "é‡è¤‡æ¤œå‡ºé–‹å§‹: $TARGET_DIR (ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º: $WINDOW)"
  
  # æ¤œå‡ºå®Ÿè¡Œ
  if [[ "$RUN_ALL" == true ]]; then
    detect_text_duplicates
    detect_structural_duplicates
    detect_pattern_duplicates
    detect_functional_duplicates
    detect_basic_duplicates
  else
    [[ "$RUN_TEXT" == true ]] && detect_text_duplicates
    [[ "$RUN_STRUCTURAL" == true ]] && detect_structural_duplicates
    [[ "$RUN_PATTERNS" == true ]] && detect_pattern_duplicates
    [[ "$RUN_FUNCTIONAL" == true ]] && detect_functional_duplicates
    [[ "$RUN_BASIC" == true ]] && detect_basic_duplicates
  fi
  
  finalize_output
}

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
main "$@"\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/basic_hashes_${window_size}" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "BASIC_DUPLICATE" "$hash" "$locations" "$window_size"
      fi
    done
  fi
}

# çµæœå‡ºåŠ›ã®åˆæœŸåŒ–
init_output() {
  case "$OUTPUT_FORMAT" in
    json)
      echo "[" > "$RESULTS/output.json"
      ;;
    csv)
      echo "type,hash,locations" > "$RESULTS/output.csv"
      ;;
  esac
}

# çµæœå‡ºåŠ›ã®çµ‚äº†å‡¦ç†
finalize_output() {
  case "$OUTPUT_FORMAT" in
    json)
      # æœ€å¾Œã®ã‚«ãƒ³ãƒã‚’å‰Šé™¤ã—ã¦JSONã‚’é–‰ã˜ã‚‹
      if [[ -s "$RESULTS/output.json" ]]; then
        sed -i '$ s/,$//' "$RESULTS/output.json" 2>/dev/null || true
      fi
      echo "]" >> "$RESULTS/output.json"
      cat "$RESULTS/output.json"
      ;;
    csv)
      cat "$RESULTS/output.csv"
      ;;
    console)
      section "æ¤œå‡ºå®Œäº†"
      info "é‡è¤‡æ¤œå‡ºå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ"
      ;;
  esac
}

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
main() {
  parse_arguments "$@"
  setup_platform
  setup_temp
  prepare_files
  init_output
  
  info "é‡è¤‡æ¤œå‡ºé–‹å§‹: $TARGET_DIR (ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º: $WINDOW)"
  
  # æ¤œå‡ºå®Ÿè¡Œ
  if [[ "$RUN_ALL" == true ]]; then
    detect_text_duplicates
    detect_structural_duplicates
    detect_pattern_duplicates
    detect_functional_duplicates
    detect_basic_duplicates
  else
    [[ "$RUN_TEXT" == true ]] && detect_text_duplicates
    [[ "$RUN_STRUCTURAL" == true ]] && detect_structural_duplicates
    [[ "$RUN_PATTERNS" == true ]] && detect_pattern_duplicates
    [[ "$RUN_FUNCTIONAL" == true ]] && detect_functional_duplicates
    [[ "$RUN_BASIC" == true ]] && detect_basic_duplicates
  fi
  
  finalize_output
}

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
main "$@"\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/text_hashes_${window_size}" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "TEXT_MULTILINE" "$hash" "$locations" "$window_size"
      fi
    done
  fi
  
  # 2. æ–‡å­—åˆ—ãƒªãƒ†ãƒ©ãƒ«é‡è¤‡
  log "æ–‡å­—åˆ—ãƒªãƒ†ãƒ©ãƒ«é‡è¤‡æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f -exec grep -Hn "\"STR\"" {} \; | \
  while IFS=: read -r file line content; do
    local pattern_hash
    pattern_hash=$(echo "$content" | $HASH_CMD | cut -d' ' -f1)
    echo "$pattern_hash	$file:$line"
  done | sort | uniq -d | while IFS=

# æ§‹é€ çš„é‡è¤‡æ¤œå‡º
detect_structural_duplicates() {
  section "æ§‹é€ çš„é‡è¤‡æ¤œå‡º"
  
  # 1. åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼é‡è¤‡ï¼ˆif-elseï¼‰
  log "if-elseæ§‹é€ é‡è¤‡æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    grep -n "if\|else" "$f" | while IFS=: read -r line_num content; do
      local normalized
      normalized=$(echo "$content" | sed -E 's/VAR[0-9]*/VAR/g; s/NUM/NUM/g; s/[[:space:]]+//g')
      local hash
      hash=$(echo "$normalized" | $HASH_CMD | cut -d' ' -f1)
      echo "$hash	$f:$line_num"
    done
  done > "$TMP/structural_if"
  
  if [[ -s "$TMP/structural_if" ]]; then
    sort "$TMP/structural_if" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/structural_if" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "STRUCTURAL_IF" "$hash" "$locations"
      fi
    done
  fi
  
  # 2. ãƒ«ãƒ¼ãƒ—æ§‹é€ é‡è¤‡
  log "ãƒ«ãƒ¼ãƒ—æ§‹é€ é‡è¤‡æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    grep -n "for\|while" "$f" | while IFS=: read -r line_num content; do
      local normalized
      normalized=$(echo "$content" | sed -E 's/VAR[0-9]*/VAR/g; s/NUM/NUM/g; s/[[:space:]]+//g')
      local hash
      hash=$(echo "$normalized" | $HASH_CMD | cut -d' ' -f1)
      echo "$hash	$f:$line_num"
    done
  done > "$TMP/structural_loop"
  
  if [[ -s "$TMP/structural_loop" ]]; then
    sort "$TMP/structural_loop" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/structural_loop" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "STRUCTURAL_LOOP" "$hash" "$locations"
      fi
    done
  fi
}

# ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹é‡è¤‡æ¤œå‡º
detect_pattern_duplicates() {
  section "ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹é‡è¤‡æ¤œå‡º"
  
  # 1. é…åˆ—æ“ä½œãƒ‘ã‚¿ãƒ¼ãƒ³
  log "é…åˆ—æ“ä½œãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    grep -n "\.map\|\.filter\|\.reduce" "$f" | while IFS=: read -r line_num content; do
      local pattern
      pattern=$(echo "$content" | sed -E 's/\.map\([^)]*\)/.map(F)/g; s/\.filter\([^)]*\)/.filter(F)/g; s/\.reduce\([^)]*\)/.reduce(F)/g')
      local hash
      hash=$(echo "$pattern" | $HASH_CMD | cut -d' ' -f1)
      echo "$hash	$f:$line_num"
    done
  done > "$TMP/pattern_array"
  
  if [[ -s "$TMP/pattern_array" ]]; then
    sort "$TMP/pattern_array" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/pattern_array" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "PATTERN_ARRAY" "$hash" "$locations"
      fi
    done
  fi
  
  # 2. Promiseãƒã‚§ãƒ¼ãƒ³
  log "Promiseãƒã‚§ãƒ¼ãƒ³æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    grep -n "\.then\|\.catch" "$f" | while IFS=: read -r line_num content; do
      local pattern
      pattern=$(echo "$content" | sed -E 's/\.then\([^)]*\)/.then(F)/g; s/\.catch\([^)]*\)/.catch(F)/g')
      local hash
      hash=$(echo "$pattern" | $HASH_CMD | cut -d' ' -f1)
      echo "$hash	$f:$line_num"
    done
  done > "$TMP/pattern_promise"
  
  if [[ -s "$TMP/pattern_promise" ]]; then
    sort "$TMP/pattern_promise" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/pattern_promise" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "PATTERN_PROMISE" "$hash" "$locations"
      fi
    done
  fi
}

# é–¢æ•°çš„é‡è¤‡æ¤œå‡º
detect_functional_duplicates() {
  section "é–¢æ•°çš„é‡è¤‡æ¤œå‡º"
  
  # 1. é–¢æ•°å®šç¾©é‡è¤‡
  log "é–¢æ•°å®šç¾©é‡è¤‡æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    grep -n "function\|=>" "$f" | while IFS=: read -r line_num content; do
      local normalized
      normalized=$(echo "$content" | sed -E 's/function[[:space:]]+VAR/function VAR/g; s/VAR[0-9]*/VAR/g; s/[[:space:]]+//g')
      local hash
      hash=$(echo "$normalized" | $HASH_CMD | cut -d' ' -f1)
      echo "$hash	$f:$line_num"
    done
  done > "$TMP/functional_def"
  
  if [[ -s "$TMP/functional_def" ]]; then
    sort "$TMP/functional_def" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/functional_def" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "FUNCTIONAL_DEF" "$hash" "$locations"
      fi
    done
  fi
}

# åŸºæœ¬çš„é‡è¤‡æ¤œå‡º
detect_basic_duplicates() {
  section "åŸºæœ¬çš„é‡è¤‡æ¤œå‡º"
  
  # å¤šè¡Œé‡è¤‡ï¼ˆç°¡æ˜“ç‰ˆï¼‰
  log "åŸºæœ¬å¤šè¡Œé‡è¤‡æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    awk -v window="$WINDOW" -v file="$f" '
    {
      for(i=1; i<=NF; i++) {
        if (NF >= window) {
          block = ""
          for(j=i; j<i+window && j<=NF; j++) {
            block = block $j " "
          }
          if (length(block) > 10) {
            cmd = "echo \"" block "\" | '"$HASH_CMD"'"
            cmd | getline hash
            close(cmd)
            print substr(hash, 1, 32) "\t" file ":" NR
          }
        }
      }
    }
    ' "$f"
  done > "$TMP/basic_hashes"
  
  if [[ -s "$TMP/basic_hashes" ]]; then
    sort "$TMP/basic_hashes" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/basic_hashes" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "BASIC_DUPLICATE" "$hash" "$locations"
      fi
    done
  fi
}

# çµæœå‡ºåŠ›ã®åˆæœŸåŒ–
init_output() {
  case "$OUTPUT_FORMAT" in
    json)
      echo "[" > "$RESULTS/output.json"
      ;;
    csv)
      echo "type,hash,locations" > "$RESULTS/output.csv"
      ;;
  esac
}

# çµæœå‡ºåŠ›ã®çµ‚äº†å‡¦ç†
finalize_output() {
  case "$OUTPUT_FORMAT" in
    json)
      # æœ€å¾Œã®ã‚«ãƒ³ãƒã‚’å‰Šé™¤ã—ã¦JSONã‚’é–‰ã˜ã‚‹
      if [[ -s "$RESULTS/output.json" ]]; then
        sed -i '$ s/,$//' "$RESULTS/output.json" 2>/dev/null || true
      fi
      echo "]" >> "$RESULTS/output.json"
      cat "$RESULTS/output.json"
      ;;
    csv)
      cat "$RESULTS/output.csv"
      ;;
    console)
      section "æ¤œå‡ºå®Œäº†"
      info "é‡è¤‡æ¤œå‡ºå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ"
      ;;
  esac
}

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
main() {
  parse_arguments "$@"
  setup_platform
  setup_temp
  prepare_files
  init_output
  
  info "é‡è¤‡æ¤œå‡ºé–‹å§‹: $TARGET_DIR (ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º: $WINDOW)"
  
  # æ¤œå‡ºå®Ÿè¡Œ
  if [[ "$RUN_ALL" == true ]]; then
    detect_text_duplicates
    detect_structural_duplicates
    detect_pattern_duplicates
    detect_functional_duplicates
    detect_basic_duplicates
  else
    [[ "$RUN_TEXT" == true ]] && detect_text_duplicates
    [[ "$RUN_STRUCTURAL" == true ]] && detect_structural_duplicates
    [[ "$RUN_PATTERNS" == true ]] && detect_pattern_duplicates
    [[ "$RUN_FUNCTIONAL" == true ]] && detect_functional_duplicates
    [[ "$RUN_BASIC" == true ]] && detect_basic_duplicates
  fi
  
  finalize_output
}

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
main "$@"\t' read -r hash location; do
    local locations
    locations=$(grep "^$hash" <(find "$NORM" -name "*.js" -type f -exec grep -Hn "\"STR\"" {} \; | \
    while IFS=: read -r file line content; do
      local pattern_hash
      pattern_hash=$(echo "$content" | $HASH_CMD | cut -d' ' -f1)
      echo "$pattern_hash	$file:$line"
    done) | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
    output_result "TEXT_STRING" "$hash" "$locations" "$window_size"
  done
}

# æ§‹é€ çš„é‡è¤‡æ¤œå‡º
detect_structural_duplicates() {
  section "æ§‹é€ çš„é‡è¤‡æ¤œå‡º"
  
  # 1. åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼é‡è¤‡ï¼ˆif-elseï¼‰
  log "if-elseæ§‹é€ é‡è¤‡æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    grep -n "if\|else" "$f" | while IFS=: read -r line_num content; do
      local normalized
      normalized=$(echo "$content" | sed -E 's/VAR[0-9]*/VAR/g; s/NUM/NUM/g; s/[[:space:]]+//g')
      local hash
      hash=$(echo "$normalized" | $HASH_CMD | cut -d' ' -f1)
      echo "$hash	$f:$line_num"
    done
  done > "$TMP/structural_if"
  
  if [[ -s "$TMP/structural_if" ]]; then
    sort "$TMP/structural_if" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/structural_if" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "STRUCTURAL_IF" "$hash" "$locations"
      fi
    done
  fi
  
  # 2. ãƒ«ãƒ¼ãƒ—æ§‹é€ é‡è¤‡
  log "ãƒ«ãƒ¼ãƒ—æ§‹é€ é‡è¤‡æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    grep -n "for\|while" "$f" | while IFS=: read -r line_num content; do
      local normalized
      normalized=$(echo "$content" | sed -E 's/VAR[0-9]*/VAR/g; s/NUM/NUM/g; s/[[:space:]]+//g')
      local hash
      hash=$(echo "$normalized" | $HASH_CMD | cut -d' ' -f1)
      echo "$hash	$f:$line_num"
    done
  done > "$TMP/structural_loop"
  
  if [[ -s "$TMP/structural_loop" ]]; then
    sort "$TMP/structural_loop" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/structural_loop" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "STRUCTURAL_LOOP" "$hash" "$locations"
      fi
    done
  fi
}

# ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹é‡è¤‡æ¤œå‡º
detect_pattern_duplicates() {
  section "ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹é‡è¤‡æ¤œå‡º"
  
  # 1. é…åˆ—æ“ä½œãƒ‘ã‚¿ãƒ¼ãƒ³
  log "é…åˆ—æ“ä½œãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    grep -n "\.map\|\.filter\|\.reduce" "$f" | while IFS=: read -r line_num content; do
      local pattern
      pattern=$(echo "$content" | sed -E 's/\.map\([^)]*\)/.map(F)/g; s/\.filter\([^)]*\)/.filter(F)/g; s/\.reduce\([^)]*\)/.reduce(F)/g')
      local hash
      hash=$(echo "$pattern" | $HASH_CMD | cut -d' ' -f1)
      echo "$hash	$f:$line_num"
    done
  done > "$TMP/pattern_array"
  
  if [[ -s "$TMP/pattern_array" ]]; then
    sort "$TMP/pattern_array" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/pattern_array" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "PATTERN_ARRAY" "$hash" "$locations"
      fi
    done
  fi
  
  # 2. Promiseãƒã‚§ãƒ¼ãƒ³
  log "Promiseãƒã‚§ãƒ¼ãƒ³æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    grep -n "\.then\|\.catch" "$f" | while IFS=: read -r line_num content; do
      local pattern
      pattern=$(echo "$content" | sed -E 's/\.then\([^)]*\)/.then(F)/g; s/\.catch\([^)]*\)/.catch(F)/g')
      local hash
      hash=$(echo "$pattern" | $HASH_CMD | cut -d' ' -f1)
      echo "$hash	$f:$line_num"
    done
  done > "$TMP/pattern_promise"
  
  if [[ -s "$TMP/pattern_promise" ]]; then
    sort "$TMP/pattern_promise" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/pattern_promise" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "PATTERN_PROMISE" "$hash" "$locations"
      fi
    done
  fi
}

# é–¢æ•°çš„é‡è¤‡æ¤œå‡º
detect_functional_duplicates() {
  section "é–¢æ•°çš„é‡è¤‡æ¤œå‡º"
  
  # 1. é–¢æ•°å®šç¾©é‡è¤‡
  log "é–¢æ•°å®šç¾©é‡è¤‡æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    grep -n "function\|=>" "$f" | while IFS=: read -r line_num content; do
      local normalized
      normalized=$(echo "$content" | sed -E 's/function[[:space:]]+VAR/function VAR/g; s/VAR[0-9]*/VAR/g; s/[[:space:]]+//g')
      local hash
      hash=$(echo "$normalized" | $HASH_CMD | cut -d' ' -f1)
      echo "$hash	$f:$line_num"
    done
  done > "$TMP/functional_def"
  
  if [[ -s "$TMP/functional_def" ]]; then
    sort "$TMP/functional_def" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/functional_def" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "FUNCTIONAL_DEF" "$hash" "$locations"
      fi
    done
  fi
}

# åŸºæœ¬çš„é‡è¤‡æ¤œå‡º
detect_basic_duplicates() {
  section "åŸºæœ¬çš„é‡è¤‡æ¤œå‡º"
  
  # å¤šè¡Œé‡è¤‡ï¼ˆç°¡æ˜“ç‰ˆï¼‰
  log "åŸºæœ¬å¤šè¡Œé‡è¤‡æ¤œå‡ºä¸­"
  
  find "$NORM" -name "*.js" -type f | while read -r f; do
    awk -v window="$WINDOW" -v file="$f" '
    {
      for(i=1; i<=NF; i++) {
        if (NF >= window) {
          block = ""
          for(j=i; j<i+window && j<=NF; j++) {
            block = block $j " "
          }
          if (length(block) > 10) {
            cmd = "echo \"" block "\" | '"$HASH_CMD"'"
            cmd | getline hash
            close(cmd)
            print substr(hash, 1, 32) "\t" file ":" NR
          }
        }
      }
    }
    ' "$f"
  done > "$TMP/basic_hashes"
  
  if [[ -s "$TMP/basic_hashes" ]]; then
    sort "$TMP/basic_hashes" | uniq -d | while IFS=$'\t' read -r hash location; do
      local locations
      locations=$(grep "^$hash" "$TMP/basic_hashes" | cut -f2 | sort | tr '\n' ',' | sed 's/,$//')
      if [[ $(echo "$locations" | tr ',' '\n' | wc -l) -gt 1 ]]; then
        output_result "BASIC_DUPLICATE" "$hash" "$locations"
      fi
    done
  fi
}

# çµæœå‡ºåŠ›ã®åˆæœŸåŒ–
init_output() {
  case "$OUTPUT_FORMAT" in
    json)
      echo "[" > "$RESULTS/output.json"
      ;;
    csv)
      echo "type,hash,locations" > "$RESULTS/output.csv"
      ;;
  esac
}

# çµæœå‡ºåŠ›ã®çµ‚äº†å‡¦ç†
finalize_output() {
  case "$OUTPUT_FORMAT" in
    json)
      # æœ€å¾Œã®ã‚«ãƒ³ãƒã‚’å‰Šé™¤ã—ã¦JSONã‚’é–‰ã˜ã‚‹
      if [[ -s "$RESULTS/output.json" ]]; then
        sed -i '$ s/,$//' "$RESULTS/output.json" 2>/dev/null || true
      fi
      echo "]" >> "$RESULTS/output.json"
      cat "$RESULTS/output.json"
      ;;
    csv)
      cat "$RESULTS/output.csv"
      ;;
    console)
      section "æ¤œå‡ºå®Œäº†"
      info "é‡è¤‡æ¤œå‡ºå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ"
      ;;
  esac
}

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
main() {
  parse_arguments "$@"
  setup_platform
  setup_temp
  prepare_files
  init_output
  
  info "é‡è¤‡æ¤œå‡ºé–‹å§‹: $TARGET_DIR (ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º: $WINDOW)"
  
  # æ¤œå‡ºå®Ÿè¡Œ
  if [[ "$RUN_ALL" == true ]]; then
    detect_text_duplicates
    detect_structural_duplicates
    detect_pattern_duplicates
    detect_functional_duplicates
    detect_basic_duplicates
  else
    [[ "$RUN_TEXT" == true ]] && detect_text_duplicates
    [[ "$RUN_STRUCTURAL" == true ]] && detect_structural_duplicates
    [[ "$RUN_PATTERNS" == true ]] && detect_pattern_duplicates
    [[ "$RUN_FUNCTIONAL" == true ]] && detect_functional_duplicates
    [[ "$RUN_BASIC" == true ]] && detect_basic_duplicates
  fi
  
  finalize_output
}

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
main "$@"